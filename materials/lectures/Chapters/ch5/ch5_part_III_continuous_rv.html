<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>ch5_part_III_continuous_rv.utf8.md</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">





class: center, middle, inverse
layout: yes
name: inverse

## STAT 305: Chapter 5 
### Part III
### Amin Shirazi
.footnote[Course page: [ashirazist.github.io/stat305.github.io](https://ashirazist.github.io/stat305.github.io/)]  
---
layout: true
class: center, middle, inverse
---
# Continuous Random Variables
## Terminology, Use, and Common Distributions
---
# What is a Continuous Random Variable?
---
layout:false
.left-column[
## Background
### What?
]
.right-column[
## Background on Continuous Random Variable

Along with discrete random variables, we have continuous random variables. While discrete random variables take one specific values from a _discrete_ (aka countable) set of possible real-number values, continous random variables take values over intervals of real numbers.

&gt;**def: Continuous random variable ** &lt;/br&gt;
&gt;A continuous random variable is a random variable which takes values on a continuous interval of real numbers.

The reason we treat them differently has mainly to do with the differences in how the math behaves: now that we are dealing with interval ranges, we change summations to integrals.
]
---
layout:false
.left-column[
## Background
### What?
]
.right-column[


###Examples of continuous random variable:


&gt; **Z** is the amount of torque required to lossen the next bold (not rounded)

&gt; **T** is the time you will wait for the next bus

&gt; **C** is the outside temprature at 11:49 pm tomorrow

&gt; **L** is the length of the next manufactured metal bar

&gt; **V** is the `\(%\)` yield of the next run of process

]


---
layout: true
class: center, middle, inverse
---
# Terminology and Usage
---
layout:false
.left-column[
## Background
## Terminology
### pdf
]
.right-column[
### Probability Density Function

Since we are now taking values over an interval, we can not "add up" probabilities with our probability function anymore. Instead, we need a new function to describe probability:

&gt;**def: probability density function** &lt;/br&gt;
&gt;A probability density function (pdf) defines the way the probability of a continuous random variable is distributed across the interval of values it can take. Since it represents probability, the probability function must always be non-negative. Regions of higher density have higher probability.

]
---

layout:false
.left-column[
## Background
## Terminology
### pdf
]
.right-column[
### Probability Density Function
####Validity of a *pdf*
Any function that satisfies the following can be a probability density function:

1. `\(\int_{-\infty}^{\infty} f(x) dx = 1\)`

2. `\(f(x) \ge 0\)` for all `\(x\)` in `\((-\infty, \infty)\)`


 and such that for all `\(a \le b\)`,
    `$$P(a \le X \le b) = P(a \le X &lt; b) =\\ P(a &lt; X \le b) = P(a &lt; X &lt; b)\\ =\int\limits_a^bf(x)dx.$$`

]
---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
]
.right-column[
### Probability Density Function

With continuous random variables, we use pdfs to get probabilities as follows:

&gt;For a continuous random variable `\(X\)` with probability density function `\(f(x)\)`, 
&gt;$$P(a \le X \le b) = \int_{a}^{b} f(x) dx$$`
&gt;for any real values `\(a, b\)` such that `\(a\le b\)`

![](ch5_part_III_continuous_rv_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;


]
---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
]
.right-column[

###Example

Consider a de-magnetized compass needle mounted at its center so that it can spin freely.  It is spun clockwise and when it comes to rest the angle, `\(\theta\)`, from the vertical, is measured. Let 
`$$Y = \text{the angle measured after each spin in radians}$$`
What values can `\(Y\)` take?

&amp;nbsp;

What form makes sense for `\(f(y)\)`?

]

---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
]
.right-column[

###Example

If this form is adopted, that what must the pdf be?

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;

Using this pdf, calculate the following probabilities:
- `\(P[Y &lt; \frac{\pi}{2}]\)`


]
---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
]
.right-column[

###Example


- `\(P[\frac{\pi}{2} &lt; Y &lt; 2\pi]\)`

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;


- `\(P[Y = \frac{\pi}{6}]\)`
]
---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
### cdf
]
.right-column[
### Cumulative Density Function (**CDF**)

We also have the cumulative density function for continuous random variables:
&gt;**def: Cumulative density function (cdf)**
&gt;For a continous random variable, `\(X\)`, with pdf f(x) the cumulative density function `\(F(x)\)` is defined as the probability that `\(X\)` takes a value less than or equal to `\(x\)` which is to say
&gt;$$ F(x) = P(X \le x) = \int_{-\infty}^{x} f(t) dt $$

TRUE FACT: the Fundamental Theorem of Calculus applies here:
$$ \dfrac{d}{dx} F(x) = f(x) $$

]
---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
### cdf
]
.right-column[
### Cumulative Density Function (**CDF**)
#### Properties of CDF for continuous random variables


As with discrete random variables, `\(F\)` has the following properties:


- **F** is monotonically increasing (i.e it is never decreasing)

- `\(\lim_{x\rightarrow-\infty}{F(x)}= 0\)` and `\(\lim_{x\rightarrow+\infty}{F(x)}= 1\)` 

    - This means that `\(0\leq{F(x)}\le 1\)` for **any CDF**

- **F** is *continuous*. (instead of just right continuous in discrete form)

]
---
layout: true
class: center, middle, inverse
---
##Mean and Variance 
###of
##Continuous Random Variables
---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
### cdf
### E(X), V(X)
]
.right-column[
### Expected Value and Variance

#### Expected Value
As with discrete random variables, continuous random variables have expected values and variances:
&gt;**def: Expected Value of Continuous Random Variable** &lt;/br&gt;
&gt;For a continous random variable, `\(X\)`, with pdf f(x) the expected value (also known as the mean) is defined as
&gt;$$ E(X) = \int_{-\infty}^{\infty} x f(x) dx $$

We often use the symbol `\(\mu\)` for the mean of a random variable, since writing `\(E(X)\)` can get confusing when lots of other parenthesis are around. We also sometimes write `\(EX\)`.
]
---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
### cdf
### E(X), V(X)
]
.right-column[
### Expected Value and Variance

#### Variance
&gt;**def: Variance of Continuous Random Variable** &lt;/br&gt;
&gt;For a continous random variable, `\(X\)`, with pdf f(x) and expected value `\(\mu\)`, the variance is defined as
&gt;$$ V(X) = \int_{-\infty}^{\infty} (x - \mu)^2 \cdot f(x) dx $$
&gt;which is identical to saying
&gt;$$ V(X) = E(X^2) - E(X)^2 $$

We will sometimes use the symbol `\(\sigma^2\)` to refer to the variance and you may see the notation `\(Var X\)` or `\(VX\)` as well.
]
---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
### cdf
### E(X), V(X)
]
.right-column[
### Expected Value and Variance

#### Sdandard Deviation (SD)
We can also use the variance to get the standard deviation of the random variable:
&gt;**def: Standard Deviation of Continuous Random Variable** &lt;/br&gt;
&gt;For a continous random variable, `\(X\)`, with pdf f(x) and expected value `\(\mu\)`, the standard deviation is defined as:
&gt;$$ \sigma = \sqrt{\sigma^2} = \sqrt{\int_{-\infty}^{\infty} (x - \mu)^2 \cdot f(x) dx} $$

]
---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
]
.right-column[
### Expected Value and Variance: Example
####Library books
Let `\(X\)` denote the amount of time for which a book on `\(2\)`-hour hold reserve at a college library is checked out by a randomly selected student and suppose its density function is
$$
f(x) = \begin{cases}
0.5x &amp; 0 \le x \le 2 \\\\
0 &amp; \text{otherwise} 
\end{cases} $$

Calculate `\(\text{E}X\)` and `\(\text{Var}X\)`.


]
---
layout: true
class: center, middle, inverse
---
##An important point about Expected Value
##and Variance of Random Variables
---
layout:false
.left-column[
## Background
## Terms and Use
### pdf
]
.right-column[
### Expected Value and Variance:

For a linear function, `\(g(X) = aX + b\)`, where `\(a\)` and `\(b\)` are constants,

&gt; `\(\text{E}(aX + b)= a \text{E}(X) + b\)`
 
&gt; `\(\text{Var}(aX + b)= a^2 \text{Var}(X)\)`

e.g Let `\(X\sim Binomial(5, 0.2)\)`. What is the expected value and variance of 4X- 3?


]
---
layout: true
class: center, middle, inverse
---
# Common Distributions
## Uniform Distribution
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
]
.right-column[

## Common continuous Distributions

### Uniform Distribution

For cases where we only know/believe/assume that a value will be between two numbers but know/believe/assume _nothing_ else.

**Origin**: We know a the random variable will take a value inside a certain range, but we don't have any belief that one part of that range is more likely than another part of that range.

&gt;**Definition: Uniform random variable **&lt;/br&gt;
&gt;The random variable `\(U\)` is a uniform random variable on the interval `\([a, b]\)` if it's density is constant on `\([a, b]\)` and the probability it takes a value outside `\([a, b]\)` is 0. We say that `\(U\)` follows a uniform distribution or `\(U \sim uniform(a, b)\)`.

]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
]
.right-column[
### Uniform Distribution

&gt;**Definition: Uniform pdf** &lt;/br&gt;
&gt;If `\(U\)` is a uniform random variable on `\([a, b]\)` then the probability density function of `\(U\)` is given by
&gt;$$f(u) = \begin{cases}
&gt; \dfrac{1}{b-a} &amp; a \le u \le b \\\\
&gt; 0 &amp; o.w.
&gt; \end{cases}
&gt;$$`

With this, we can find the for any value of `\(a\)` and `\(b\)`, if `\(U \sim uniform(a, b)\)` the mean and variance are:

$$
E(U) = \frac{1}{2}(b-a)
$$

$$
Var(U) = \frac{1}{12}(b-a)^2
$$

]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
]
.right-column[
### Uniform Distribution

&gt;**Definition: Uniform cdf** &lt;/br&gt;
&gt;If `\(U\)` is a uniform random variable on `\([a, b]\)` then the cumulative density function of `\(U\)` is given by
&gt;$$F(u) = \begin{cases}
&gt; 0 &amp; u &lt; a \\\\
&gt; \dfrac{u-a}{b-a} &amp; a \le u \le b \\\\
&gt; 1 &amp; u &gt; b \\\\
&gt;\end{cases}
&gt;$$`
]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
]
.right-column[
### Uniform Distribution

A few useful notes:

- The most commonly used uniform random variable is `\(U \sim Uniform(0,1)\)`.

- Again, this is useful if we want to use a random variable that takes values within an interval, but we don't think it is likely to be in any certain region. 

- The values `\(a\)` and `\(b\)` used to determine the range in which `\(f(u)\)` is not 0 are parameters of the distribution.
]
---
layout:true
class: middle, center, inverse
---
#  Common Continuous Distributions
##Exponential Distribution

---

layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
]
.right-column[

### Exponential Distribution
**Definition: Exponential random variable **


An `\(\text{Exp}(\alpha)\)` random variable measures the waiting time until a specific event that has an equal chance of happening at any point in time. (it can be cosidered the continous version of geometric distribution)

&gt;Examples:
&gt;- Time between your arrival at the bus station and the moment that bus arrives 
&gt;
&gt;&amp;nbsp;
&gt;
&gt;- Time until the next person walks inside the park's library 
&gt;
&gt;&amp;nbsp;
&gt;
&gt;- The time (in hours) until a light bulb burns out. 


]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
]
.right-column[

### Exponential Distribution

&gt;**Definition: Exponential pdf** &lt;/br&gt;
&gt;If `\(X\)` is an exponential random variable with rate `\(\frac{1}{\alpha}\)` then the probability density function of `\(X\)` is given by
&gt;$$f(u) = \begin{cases}
&gt;\dfrac{1}{\alpha} e^{-\frac{x}{\alpha}} &amp; x \ge 0 \\\\
&gt;0 &amp; o.w.
&gt;\end{cases}$$`

![](ch5_part_III_continuous_rv_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;
]
---

layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
]
.right-column[
### Exponential Distribution

&gt;**Definition: Exponential CDF** &lt;/br&gt;
&gt;If `\(X\)` is a exponential random variable with rate `\(1/\alpha\)` then the cumulative density function of `\(X\)` is given by
&gt;$$F(x) = \begin{cases}
&gt;1 - exp(-x/\alpha) &amp; 0 \le x \\\\
&gt;0 &amp; x &lt; 0 \\\\
&gt;\end{cases}
&gt;$$`


![](ch5_part_III_continuous_rv_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

]


---
layout:true
class: middle, center, inverse
---
##Mean and Variance of
##Exponential Distribution

---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
]
.right-column[

### Exponential Distribution

&gt;**Definition: Exponential pdf** &lt;/br&gt;
&gt;If `\(X\)` is an exponential random variable with rate `\(\frac{1}{\alpha}\)` then the probability density function of `\(X\)` is given by
&gt;$$f(u) = \begin{cases}
&gt;\dfrac{1}{\alpha} e^{-\frac{x}{\alpha}} &amp; x \ge 0 \\\\
&gt;0 &amp; o.w.
&gt;\end{cases}
&gt;$$`
From this, we can derive:

$$
E(X) = \alpha
$$

$$
Var(X) = \alpha^2
$$

]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
]
.right-column[
### Exponential Distribution
**Example**: Library arrivals, cont'd

Recall the example the arrival rate of students at Parks library between 12:00 and 12:10pm early in the week to be about `\(12.5\)` students per minute. That translates to a `\(1/12.5 = .08\)` minute average waiting time between student arrivals. 

Consider observing the entrance to Parks library at exactly noon next Tuesday and define the random variable
$$
`\begin{align}
    T&amp;: \text{the waiting time (min) until the first}  \\
    &amp;  \text{student passes through the door.}\\
\end{align}`
$$


Using `\(T \sim \text{Exp}(.08)\)`, what is the probability of waiting more than `\(10\)` seconds (1/6 min) for the first arrival?


]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
]
.right-column[
### Exponential Distribution
**Example**: Library arrivals, cont'd

$$
`\begin{align}
    T&amp;: \text{the waiting time (min) until the first}  \\
    &amp;  \text{student passes through the door.}\\
\end{align}`
$$

What is the probability of waiting less than `\(5\)` seconds?



]
---
layout: true
class: center, middle, inverse
---
##Common Continous Distibutions
##Normal Distribution

---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
]
.right-column[
### The Normal distribution

We have already seen the normal distribution as a "bell shaped" distribution, but we can formalize this.


The **normal** or **Gaussian** `\((\mu, \sigma^2)\)` distribution is a continuous probability distribution with probability density function (pdf)
`$$f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x - \mu)^2/{2\sigma^2}} \qquad \text{for all } x$$`
for `\(\sigma &gt; 0\)`.

We then show that by `\(X\sim\text{N}(\mu, \sigma^2)\)`


]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
]
.right-column[
### The Normal distribution


A normal random variable is (often) a finite average of many repeated, independent, identical trials.

&gt;Mean width of the next 50 hexamine pallets
&gt;
&gt;Mean height of 30 students
&gt;
&gt;Total `\(\%\)` yield of the next 10 runs of a chemical process

]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
]
.right-column[
### Normal Distribution's Center and Shape


Regardless of the values of `\(\mu\)` and `\(\sigma^2\)`, the normal pdf has the following shape:
&lt;center&gt;
&lt;img src="normal_pdf.png" alt="normal_pdf" width="400"/&gt;
&lt;/center&gt;

In other words, the distribution is centered around `\(\mu\)` and has an inflection point at `\(\sigma = \sqrt{\sigma^2}\)`.

In this way, the value of `\(\mu\)` determines the center of our distribution and the value of `\(\sigma^2\)` deterimes the spread. 

]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
]
.right-column[
### Normal Distribution's Center and Shape

Here we can see what differences in `\(\mu\)` and `\(\sigma^2\)` do to the shape of the shape of distribution
&lt;center&gt;
&lt;img src="normal_comparisons.png" alt="normal_comparisons" width="600" height= "400"/&gt;
&lt;/center&gt;


]
---
layout: true
class: center, middle, inverse
---
##Mean and Variance 
###of 
##Normal Distribution
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
]
.right-column[
### The Normal distribution

It is not obvious, but

- `\(\int\limits_{-\infty}^\infty f(x) dx = \int\limits_{-\infty}^\infty \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x - \mu)^2/{2\sigma^2}} dx =\)`

&amp;nbsp;

- `\(\text{E}X = \int\limits_{-\infty}^\infty x \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x - \mu)^2/{2\sigma^2}} dx =\)`

&amp;nbsp;

- `\(\text{Var}X = \int\limits_{-\infty}^\infty (x - \mu)^2 \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x - \mu)^2/{2\sigma^2}} dx =\)`

]
---
layout: true
class: center, middle, inverse
---
##One poine before we go on
###*Standardization*
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
]
.right-column[
###Definition

**Standardization** is the process of transforming a random variable, `\(X\)`, into the signed number of standard deviations by which it is is above its mean value.
$$
Z = \frac{X - \text{E}X}{\text{SD}(X)}
$$


`\(Z\)` has mean `\(0\)`

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;

`\(Z\)` has variance (and standard deviation) `\(1\)`
]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
]
.right-column[

&amp;nbsp;

&amp;nbsp;

The Calculus I methods of evaluating integrals via anti-differentiation will fail when it comes to normal densities. They do not have anti-derivatives that are expressible in terms of elementary functions.

&gt; This means we cannot find probabilities of a Normally distributed random variable by hand.
&gt;
&gt;So, what is the solution?

    &gt;Use computers or tables of values.

]    
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
]
.right-column[


&amp;nbsp;

&amp;nbsp;


The use of tables for evaluating normal probabilities depends on the following relationship. If `\(X \sim \text{Normal}(\mu, \sigma^2)\)`,


`$$\begin{align}
P[a \le X \le b] &amp;= \int\limits_a^b\frac{1}{\sqrt{2\pi\sigma^2}} e^{-(x - \mu)^2/{2\sigma^2}}dx  \\
\\
&amp;= \int\limits_{(a- \mu)/\sigma}^{(b-\mu)/\sigma}\frac{1}{\sqrt{2\pi}} e^{-z^2/2}dz \\
\\
&amp;= P\left[\frac{a - \mu}{\sigma} \le Z \le \frac{b - \mu}{\sigma}\right]
\end{align}$$`

where `\(Z \sim \text{Normal}(0, 1)\)`.
]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
###Standard Normal Distribution

The parameters are important in determining the probability, but because the pdf of a normal random variable is difficult to work with we often use the distribution with `\(\mu = 0\)` and `\(\sigma^2 = 1\)` as a reference point. 

&gt;**Definition: Standard Normal Distribution** &lt;/br&gt;
&gt;The standard normal distribution is a normal distribution with `\(\mu=0\)` and `\(\sigma^2=1\)`. It has pdf
&gt;$$ 
&gt;\begin{align}
&gt;f(z) &amp;= \dfrac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2} z^2} \\\\
&gt;     &amp;= \dfrac{1}{\sqrt{2 \pi}} \exp\left(-\frac{1}{2} z^2\right) \\\\
&gt;\end{align} 
&gt;$$`

We say that a random variable is a "standard normal random variable" if it follows a standard normal distribution or that `\(Z \sim N(0, 1)\)`.
]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[

### Standard Normal Distribution (cont)

It's worth pointing out the reason why the standard normal distribution is important. There is no "closed form" for the cdf of a normal distribution. 

In other words, since we can't finish this step:
$$
F(x) = \int_{-\infty}^{x} \dfrac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{1}{2 \sigma^2} (t - \mu)^2} dt = ???
$$

we have to estimate the value each time. However, we have already done this for _standard_ normal random variables already in **Table B.3**

So if `\(Z \sim N(0, 1)\)` then `\(P(Z \le 1.5) = F(1.5) = 0.9332\)`.

The good news is that we can connect any normal probabilities to the values we have for the standard normal probabilities.

]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
### Standard Normal Distribution (cont)

These facts drive the connection between different normal random variables:

&gt;**Key Facts: Converting Normal Distributions**&lt;/br&gt;
&gt; If `\(X \sim N(\mu, \sigma^2)\)` and `\(Z = \dfrac{X - \mu}{\sigma}\)` then `\(Z \sim N(0, 1)\)`
&gt; &amp;nbsp;&lt;/br&gt;
&gt; &amp;nbsp;&lt;/br&gt;
&gt; If `\(Z \sim N(0, 1)\)` and `\(X = \sigma Z + \mu\)` then `\(X \sim N(\mu, \sigma^2)\)`

We use this connection as a way to avoid working with the normal pdf directly. 
]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Standard Normal
]
.right-column[
### Standard Normal Distribution (cont)
A rule of thumb in dealing with questions about finding probabilities of Normally distributed probabilities of `\(N(\mu, \sigma^2)\)`:

&gt;(1) Translate that question to standard Normal distribution. i.e. `\(Z\sim N(0,1)\)`
&gt;
&gt;(2) Look it up in a table

]
---

layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
###CDF of Standard Normal Distribution

The standard Normal distribution $ Z\sim N(0,1)$ plays an important rule in finding probabilities associated with a Normal random variable. The **CDF** of a standard Normal distribution is 

$$
\Phi(z) = F(z) = \int\limits_{-\infty}^z\frac{1}{\sqrt{2\pi}}e^{-t^2}dt = P(Z \leq z) .
$$

Therefore,  we can find probabilities for all normal distributions by tabulating probabilities for only the standard normal distribution. We will use a table of the **standard normal cumulative probability function**.
]

---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
### Standard Normal Distribution (cont)

**Example: Normal to Standard Normal**

If `\(X \sim N(3, 4)\)` then:
$$
`\begin{align}
P(X \le 6) &amp;= P\left(\frac{X - 3}{2} \le \frac{6 - 3}{2} \right)\\\\
                 &amp;= P(Z \le 1.5) \\\\
                 &amp;= 0.9332
\end{align}`
$$
where the valeu 0.9332 if found from **Table B.3**
]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
### Standard Normal Distribution (cont)

**Example**: Standard normal probabilities


`\(P[Z &lt; 1.76]\)`

&amp;nbsp;

&amp;nbsp;


`\(P[.57 &lt; Z &lt; 1.32]\)`
]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
&lt;center&gt;
&lt;img src="normal_table1.jpg" alt="normal_table1.jpg" width="600" height= "550"/&gt;
&lt;/center&gt;

]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
&lt;center&gt;
&lt;img src="normal_table2.jpg" alt="normal_table2.jpg" width="600" height= "550"/&gt;
&lt;/center&gt;

]
---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
### Some useful tips about standard Normal distribution

&gt;By symmetry of the standard Normal distribution around zero
&gt;   `\(P(Z\ge a)= P(Z\le -a)\)`
    
&amp;nbsp;

&amp;nbsp;

&amp;nbsp;

&gt;We can also do it reverse, find `\(z\)` such that `\(P(-z \le Z \le z)= 0.95\)`
&gt;
&gt;   `\(P(Z \geq \#)= 0.025\)`

]

---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
**Example**: Baby food

J. Fisher, in his article Computer Assisted Net Weight Control (**Quality Progress**, June 1983), discusses the filling of food containers with strained plums and tapioca by weight. The mean of the values portrayed is about `\(137.2\)`g, the standard deviation is about `\(1.6\)`g, and data look bell-shaped. Let 
$$
W = \text{the next fill weight.}
$$



Let `\(W\sim N(137.2, 1.6^2)\)`.  Find the probability that the next jar contains less food by mass than it's supposed to (declared weight = `\(135.05\)`g).
]

---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
### More example

Using the standard normal table, calculate the following:

`\(P(X &gt; 7), X \sim \text{Normal}(6, 9)\)`

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;


`\(P(|X - 1| &gt; 0.5), X \sim \text{Normal}(2, 4)\)`
]

---
layout:false
.left-column[
## Background
## Terms and Use
## Common Dists
### Uniform
### Exponential
### Normal
### Std. Normal
]
.right-column[
### More example

Find `\(c\)` such that 
`$$P(|X - 2| &gt; c) = 0.01$$`
where `\(X \sim \text{Normal}(2, 4)\)` 


]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
